{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b510ba7-99a2-49b6-8b8c-cfbb54387ef3",
   "metadata": {},
   "source": [
    "# Converting the Drainage Crossings Dataset to COCO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaeb878a-5b4f-4f29-b7b9-7259230c064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import rasterio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e60fc79-9d79-403a-94da-7da7f26acfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to dataset path, all else can then be run without modifying\n",
    "dataset_path = \"/workspace/Data_share\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a6b7bc-0272-49cb-aec2-20ea2fa4f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['CA', 'IL', 'ND', 'NE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f0f2f-8c76-41bf-8d85-38d87f0cebb0",
   "metadata": {},
   "source": [
    "## 1. Renaming files, creating a data catalog, and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02473234-7a88-47e8-b20f-b58b4193e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all image files to reflect their physical location\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea602655-efeb-4d1f-b3b6-e3bc7fc4cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename annotation directories for consistency\n",
    "os.rename(os.path.join(dataset_path, 'CA', 'annotations'), os.path.join(dataset_path, 'CA', 'CA_annotations'))\n",
    "os.rename(os.path.join(dataset_path, 'IL', 'annotations'), os.path.join(dataset_path, 'IL', 'IL_annotations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169f6910-053b-40fd-ad29-5775e7c80f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all annotation files to match their corresponding image\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_annotations')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3589dd8c-ddf4-411f-8659-0722deea0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with files, annotations, and corresponding paths\n",
    "file_list = []\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith('.tif'):\n",
    "            annotation = file[:-4]+'.xml'\n",
    "            file_list.append({\n",
    "                'filename': file, \n",
    "                'filepath':os.path.join(dirpath, file),\n",
    "                'annpath': os.path.join(dataset_path, d, f'{d}_annotations', annotation),\n",
    "                'ann': annotation\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2164fe7-3cc2-46fd-95c7-8d98f894f890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>annpath</th>\n",
       "      <th>ann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_612...</td>\n",
       "      <td>CA_612.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_341...</td>\n",
       "      <td>CA_341.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_187...</td>\n",
       "      <td>CA_1878.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_150...</td>\n",
       "      <td>CA_1504.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_221...</td>\n",
       "      <td>CA_2214.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                      filepath  \\\n",
       "0   CA_612.tif   /workspace/Data_share/CA/CA_data/CA_612.tif   \n",
       "1   CA_341.tif   /workspace/Data_share/CA/CA_data/CA_341.tif   \n",
       "2  CA_1878.tif  /workspace/Data_share/CA/CA_data/CA_1878.tif   \n",
       "3  CA_1504.tif  /workspace/Data_share/CA/CA_data/CA_1504.tif   \n",
       "4  CA_2214.tif  /workspace/Data_share/CA/CA_data/CA_2214.tif   \n",
       "\n",
       "                                             annpath          ann  \n",
       "0  /workspace/Data_share/CA/CA_annotations/CA_612...   CA_612.xml  \n",
       "1  /workspace/Data_share/CA/CA_annotations/CA_341...   CA_341.xml  \n",
       "2  /workspace/Data_share/CA/CA_annotations/CA_187...  CA_1878.xml  \n",
       "3  /workspace/Data_share/CA/CA_annotations/CA_150...  CA_1504.xml  \n",
       "4  /workspace/Data_share/CA/CA_annotations/CA_221...  CA_2214.xml  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e41ac-413c-4c19-81f3-27819000fcbc",
   "metadata": {},
   "source": [
    "## Ensure that image chips do not contain invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4339e8a7-5655-425a-aa8c-6704fe2b98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████▍                              | 3683/6013 [01:20<00:42, 54.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39669 2147483647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████              | 4948/6013 [01:46<00:22, 48.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 479.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████▉            | 5098/6013 [01:49<00:19, 47.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 458.95322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████████████████████████████████████▊           | 5158/6013 [01:50<00:18, 47.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 475.28494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████████████████▍ | 5893/6013 [02:06<00:02, 47.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 478.6593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 6013/6013 [02:08<00:00, 46.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 out of 6013 chips filtered out due to invalid pixel values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['valid'] = True\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    with rasterio.open(row['filepath'], 'r') as src:\n",
    "        data = src.read()\n",
    "    # this operation catches invalid values that are too high or too low compared to the rest of the DEM\n",
    "    df.at[index, 'valid'] = False if (np.max(data) - np.min(data)) > 10000 else True\n",
    "    if (np.max(data) - np.min(data)) > 10000:\n",
    "        print (np.min(data), np.max(data))\n",
    "\n",
    "filtered = len(df[df['valid']==False])\n",
    "\n",
    "print(f'{filtered} out of {len(df)} chips filtered out due to invalid pixel values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4dd0ab3-7665-489d-a449-a0adf06759d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['valid']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c39aff-cace-428a-9382-0bdc134e4d1e",
   "metadata": {},
   "source": [
    "## Randomly split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ca03a79-ecb1-4a1d-ac38-3b22969a7728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>annpath</th>\n",
       "      <th>ann</th>\n",
       "      <th>valid</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_612...</td>\n",
       "      <td>CA_612.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_341...</td>\n",
       "      <td>CA_341.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>validate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_187...</td>\n",
       "      <td>CA_1878.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_150...</td>\n",
       "      <td>CA_1504.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_221...</td>\n",
       "      <td>CA_2214.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                      filepath  \\\n",
       "0   CA_612.tif   /workspace/Data_share/CA/CA_data/CA_612.tif   \n",
       "1   CA_341.tif   /workspace/Data_share/CA/CA_data/CA_341.tif   \n",
       "2  CA_1878.tif  /workspace/Data_share/CA/CA_data/CA_1878.tif   \n",
       "3  CA_1504.tif  /workspace/Data_share/CA/CA_data/CA_1504.tif   \n",
       "4  CA_2214.tif  /workspace/Data_share/CA/CA_data/CA_2214.tif   \n",
       "\n",
       "                                             annpath          ann  valid  \\\n",
       "0  /workspace/Data_share/CA/CA_annotations/CA_612...   CA_612.xml   True   \n",
       "1  /workspace/Data_share/CA/CA_annotations/CA_341...   CA_341.xml   True   \n",
       "2  /workspace/Data_share/CA/CA_annotations/CA_187...  CA_1878.xml   True   \n",
       "3  /workspace/Data_share/CA/CA_annotations/CA_150...  CA_1504.xml   True   \n",
       "4  /workspace/Data_share/CA/CA_annotations/CA_221...  CA_2214.xml   True   \n",
       "\n",
       "      usage  \n",
       "0     train  \n",
       "1  validate  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly split dataset\n",
    "np.random.seed(0)\n",
    "def assign_usage(file):\n",
    "    n = np.random.rand()\n",
    "    if n < 0.7:\n",
    "        return 'train'\n",
    "    elif n < 0.9:\n",
    "        return 'validate'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "df['usage'] = df.apply(assign_usage, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371bf80-90ba-4bb3-9d1e-c918f85f226f",
   "metadata": {},
   "source": [
    "## Restructuring the data directory to conform to COCO specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0a65ab-d820-4256-9bbd-cec68ee49d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, testing, and validation directories\n",
    "output_directory = '/workspace/processed_data'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.chdir(output_directory)\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('validate', exist_ok=True)\n",
    "os.makedirs('test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67523592-eb95-4b65-bf55-cc68070a04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 6008/6008 [00:10<00:00, 591.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# use shutil to move files into directories based on the usage column\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filepath = row['filepath']\n",
    "    usage = row['usage']\n",
    "    new_path = os.path.join(output_directory, usage, f'{index}.tif')\n",
    "    shutil.copy(filepath, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56952841-a489-47ea-9ab0-e5a835d0f1ac",
   "metadata": {},
   "source": [
    "## Iterating through annotation files to create the COCO json for each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cab820f-eebb-4739-8156-00139e692b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to annotation directory\n",
    "annotation_directory = os.path.join(output_directory, 'annotations')\n",
    "os.makedirs(annotation_directory, exist_ok=True)\n",
    "os.chdir(annotation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df27b519-9933-49b0-b5b4-4ac79fc5f4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 4225/4225 [05:00<00:00, 14.05it/s]\n",
      "100%|█████████████████████████████████████| 601/601 [00:06<00:00, 92.41it/s]\n",
      "100%|███████████████████████████████████| 1182/1182 [00:24<00:00, 48.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each given directory:\n",
    "ann_number = 0\n",
    "for usage in ['train', 'test', 'validate']:\n",
    "    # initialize COCO json for the directory\n",
    "    usage_json = {}\n",
    "    info = {'year': 2024,\n",
    "            'version': 1.0,\n",
    "            'description': f'Data to {usage} drainage culvert detection task',\n",
    "            'contributor': 'none',\n",
    "            'url': 'none',\n",
    "            'date_created':None}\n",
    "    licenses = [{'id':1,\n",
    "                'url':'https://creativecommons.org/publicdomain/zero/1.0/',\n",
    "                'name':'Public Domain'}]\n",
    "    categories = [{'id':1,\n",
    "                   'name':'Drainage Culvert',\n",
    "                   'supercategory':'none'}]\n",
    "    images = []\n",
    "    annotations = []\n",
    "    # get a dataframe of only files for a given usage\n",
    "    usage_df = df[df['usage'] == usage]\n",
    "    for index, row in tqdm(usage_df.iterrows(), total=len(usage_df)):\n",
    "        # add image information to json\n",
    "        image_dict = {'id':index,\n",
    "                      'license':1,\n",
    "                      'file_name':f'{index}.tif',\n",
    "                      'height':800,\n",
    "                      'width':800,\n",
    "                      'date_captured':'none'}\n",
    "        images.append(image_dict)\n",
    "        # load in annotation xml to dict\n",
    "        tree = ET.parse(row['annpath'])\n",
    "        root = tree.getroot()\n",
    "\n",
    "        \n",
    "        # extract bounding box from dictionary and append to json as annotation\n",
    "        for bbox in root.findall('object'):\n",
    "            xmin = int(bbox.find('bndbox/xmin').text)\n",
    "            ymin = int(bbox.find('bndbox/ymin').text)\n",
    "            xmax = int(bbox.find('bndbox/xmax').text)\n",
    "            ymax = int(bbox.find('bndbox/ymax').text)\n",
    "            \n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "            annotation_dict = {'id': ann_number,\n",
    "                          'image_id':index,\n",
    "                          'category_id': 1,\n",
    "                          'bbox': [xmin, ymax, width, height],\n",
    "                          'area': width*height,\n",
    "                          'segmentation':[],\n",
    "                          'iscrowd':0}\n",
    "            annotations.append(annotation_dict)\n",
    "            ann_number += 1\n",
    "        usage_json['info'] = info\n",
    "        usage_json['licenses'] = licenses\n",
    "        usage_json['categories'] = categories\n",
    "        usage_json['images'] = images\n",
    "        usage_json['annotations'] = annotations\n",
    "        \n",
    "        json_data = json.dumps(usage_json, indent=4)\n",
    "\n",
    "        \n",
    "    with open(f'{usage}.json', 'w') as json_file:\n",
    "        json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c274de9-a4f4-4afe-bd92-b8aab7db9c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
