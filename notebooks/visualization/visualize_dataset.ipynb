{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "966e735e-3cf8-4c10-9749-328a6725b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import rasterio\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('/workspace/Transformer_OD_TPU'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "13386d3b-279b-4b6d-8852-21b1c1c1b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0be9f01d-410c-44f1-8e05-f1bec3305d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3005575d-f06f-4099-994e-4efcc1b4fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "from engine import evaluate, train_one_epoch\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e6c5d641-3879-4336-972a-2d3b45c0dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7f2ca079-be9f-411f-8880-a80d3f8b5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'detr_output_3'\n",
    "output_dir = os.path.join('/workspace',experiment)\n",
    "vis_dir = os.path.join('/workspace/visualizations',experiment,'val_outputs')\n",
    "os.makedirs(vis_dir, exist_ok=True)\n",
    "\n",
    "if 'scratch' in (output_dir):\n",
    "    sys.argv =  ['main.py', '--num_classes', '2', '--coco_path', '/workspace/processed_data', '--num_workers', '0', '--resume', f'{output_dir}/best_checkpoint.pth', '--batch_size', '1']\n",
    "else:\n",
    "    sys.argv = ['main.py', '--coco_path', '/workspace/processed_data', '--num_workers', '0', '--resume', f'{output_dir}/best_checkpoint.pth', '--batch_size', '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d3b443c-c520-40a6-8fc6-4a287c1ba0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = main.get_args_parser()\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "31e22900-881f-405e-9c09-a2925f337f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_train = build_dataset(image_set='train', args=args)\n",
    "dataset_val = build_dataset(image_set='val', args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "925fc049-97d3-4676-90cb-fbc71fcbfc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "sampler_val = torch.utils.data.RandomSampler(dataset_val)\n",
    "\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "    sampler_train, args.batch_size, drop_last=True)\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train,\n",
    "                                collate_fn=utils.collate_fn, num_workers=args.num_workers)\n",
    "data_loader_val = DataLoader(dataset_val, args.batch_size, sampler=sampler_val,\n",
    "                            drop_last=False, collate_fn=utils.collate_fn, num_workers=args.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27edb728-9cf4-417c-a09a-503d20131a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.device)\n",
    "model, criterion, postprocessors = build_model(args)\n",
    "model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c93b3f86-e954-4a14-a13a-7cb303bc0855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31c7a056-dc7b-43d0-9ff1-1e2acaf65cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(sample, prob, boxes, idx):\n",
    "    image = sample[0].tensors[0].cpu().numpy()[0,:,:]\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(image, cmap='Greys_r')\n",
    "    ax = plt.gca()\n",
    "    for p, (xmin, ymin, xmax, ymax) in zip(prob, boxes.tolist()):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color='r', linewidth=3))\n",
    "        cl = p.argmax()\n",
    "        text = f'{p[cl]:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='red', alpha=0.8))\n",
    "    \n",
    "    input_bbox_rescale = rescale_bboxes(sample[1][0]['boxes'].to(device))\n",
    "    for (xmin, ymin, xmax, ymax) in input_bbox_rescale.tolist():\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color='g', linewidth=3))\n",
    "\n",
    "    plt.savefig(os.path.join(vis_dir,f'{idx}_output.png'))\n",
    "    plt.close()\n",
    "\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox):\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([800., 800., 800., 800.], dtype=torch.float32).to(device)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e055b7df-2cc6-4d66-b976-a202dfb39637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1182/1182 [00:38<00:00, 30.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, sample in enumerate(tqdm(data_loader_val)):\n",
    "    if idx % 50 != 0:\n",
    "        continue\n",
    "    samples, targets = sample\n",
    "    samples = samples.to(device)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    outputs = model(samples)\n",
    "    \n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "    keep = probas.max(-1).values > 0.7\n",
    "    \n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep])\n",
    "    \n",
    "    plot_results(sample, probas[keep], bboxes_scaled, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84278664-f514-4571-98d4-473a97d35a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
