{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b510ba7-99a2-49b6-8b8c-cfbb54387ef3",
   "metadata": {},
   "source": [
    "# Converting the Drainage Crossings Dataset to COCO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaeb878a-5b4f-4f29-b7b9-7259230c064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "import rasterio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e60fc79-9d79-403a-94da-7da7f26acfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to dataset path, all else can then be run without modifying\n",
    "dataset_path = \"/workspace/Data_share/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a6b7bc-0272-49cb-aec2-20ea2fa4f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['CA', 'IL', 'NE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f0f2f-8c76-41bf-8d85-38d87f0cebb0",
   "metadata": {},
   "source": [
    "## 1. Renaming files, creating a data catalog, and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02473234-7a88-47e8-b20f-b58b4193e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all image files to reflect their physical location\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea602655-efeb-4d1f-b3b6-e3bc7fc4cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename annotation directories for consistency\n",
    "os.rename(os.path.join(dataset_path, 'CA', 'annotations'), os.path.join(dataset_path, 'CA', 'CA_annotations'))\n",
    "os.rename(os.path.join(dataset_path, 'IL', 'annotations'), os.path.join(dataset_path, 'IL', 'IL_annotations'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169f6910-053b-40fd-ad29-5775e7c80f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all annotation files to match their corresponding image\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_annotations')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3589dd8c-ddf4-411f-8659-0722deea0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with files, annotations, and corresponding paths\n",
    "file_list = []\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith('.tif'):\n",
    "            annotation = file[:-4]+'.xml'\n",
    "            file_list.append({\n",
    "                'filename': file, \n",
    "                'filepath':os.path.join(dirpath, file),\n",
    "                'annpath': os.path.join(dataset_path, d, f'{d}_annotations', annotation),\n",
    "                'ann': annotation\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2164fe7-3cc2-46fd-95c7-8d98f894f890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>annpath</th>\n",
       "      <th>ann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_612...</td>\n",
       "      <td>CA_612.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_341...</td>\n",
       "      <td>CA_341.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_187...</td>\n",
       "      <td>CA_1878.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_150...</td>\n",
       "      <td>CA_1504.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_221...</td>\n",
       "      <td>CA_2214.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                      filepath  \\\n",
       "0   CA_612.tif   /workspace/Data_share/CA/CA_data/CA_612.tif   \n",
       "1   CA_341.tif   /workspace/Data_share/CA/CA_data/CA_341.tif   \n",
       "2  CA_1878.tif  /workspace/Data_share/CA/CA_data/CA_1878.tif   \n",
       "3  CA_1504.tif  /workspace/Data_share/CA/CA_data/CA_1504.tif   \n",
       "4  CA_2214.tif  /workspace/Data_share/CA/CA_data/CA_2214.tif   \n",
       "\n",
       "                                             annpath          ann  \n",
       "0  /workspace/Data_share/CA/CA_annotations/CA_612...   CA_612.xml  \n",
       "1  /workspace/Data_share/CA/CA_annotations/CA_341...   CA_341.xml  \n",
       "2  /workspace/Data_share/CA/CA_annotations/CA_187...  CA_1878.xml  \n",
       "3  /workspace/Data_share/CA/CA_annotations/CA_150...  CA_1504.xml  \n",
       "4  /workspace/Data_share/CA/CA_annotations/CA_221...  CA_2214.xml  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7e41ac-413c-4c19-81f3-27819000fcbc",
   "metadata": {},
   "source": [
    "## Ensure that image chips do not contain invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4339e8a7-5655-425a-aa8c-6704fe2b98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████       | 4336/5400 [01:35<00:21, 48.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 479.9973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████      | 4487/5400 [01:38<00:18, 48.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 458.95322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████▍     | 4543/5400 [01:39<00:17, 48.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 475.28494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████▏| 5279/5400 [01:55<00:02, 47.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.402823e+38 478.6593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 5400/5400 [01:57<00:00, 45.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 out of 5400 chips filtered out due to invalid pixel values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['valid'] = True\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    with rasterio.open(row['filepath'], 'r') as src:\n",
    "        data = src.read()\n",
    "    # this operation catches invalid values that are too high or too low compared to the rest of the DEM\n",
    "    df.at[index, 'valid'] = False if (np.max(data) - np.min(data)) > 10000 else True\n",
    "    if (np.max(data) - np.min(data)) > 10000:\n",
    "        print (np.min(data), np.max(data))\n",
    "\n",
    "filtered = len(df[df['valid']==False])\n",
    "\n",
    "print(f'{filtered} out of {len(df)} chips filtered out due to invalid pixel values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4dd0ab3-7665-489d-a449-a0adf06759d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['valid']==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c39aff-cace-428a-9382-0bdc134e4d1e",
   "metadata": {},
   "source": [
    "## Randomly split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca03a79-ecb1-4a1d-ac38-3b22969a7728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>annpath</th>\n",
       "      <th>ann</th>\n",
       "      <th>valid</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_612.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_612...</td>\n",
       "      <td>CA_612.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_341.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_341...</td>\n",
       "      <td>CA_341.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>validate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1878.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_187...</td>\n",
       "      <td>CA_1878.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_1504.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_150...</td>\n",
       "      <td>CA_1504.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_data/CA_2214.tif</td>\n",
       "      <td>/workspace/Data_share/CA/CA_annotations/CA_221...</td>\n",
       "      <td>CA_2214.xml</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                      filepath  \\\n",
       "0   CA_612.tif   /workspace/Data_share/CA/CA_data/CA_612.tif   \n",
       "1   CA_341.tif   /workspace/Data_share/CA/CA_data/CA_341.tif   \n",
       "2  CA_1878.tif  /workspace/Data_share/CA/CA_data/CA_1878.tif   \n",
       "3  CA_1504.tif  /workspace/Data_share/CA/CA_data/CA_1504.tif   \n",
       "4  CA_2214.tif  /workspace/Data_share/CA/CA_data/CA_2214.tif   \n",
       "\n",
       "                                             annpath          ann  valid  \\\n",
       "0  /workspace/Data_share/CA/CA_annotations/CA_612...   CA_612.xml   True   \n",
       "1  /workspace/Data_share/CA/CA_annotations/CA_341...   CA_341.xml   True   \n",
       "2  /workspace/Data_share/CA/CA_annotations/CA_187...  CA_1878.xml   True   \n",
       "3  /workspace/Data_share/CA/CA_annotations/CA_150...  CA_1504.xml   True   \n",
       "4  /workspace/Data_share/CA/CA_annotations/CA_221...  CA_2214.xml   True   \n",
       "\n",
       "      usage  \n",
       "0     train  \n",
       "1  validate  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly split dataset\n",
    "np.random.seed(0)\n",
    "def assign_usage(file):\n",
    "    n = np.random.rand()\n",
    "    if n < 0.7:\n",
    "        return 'train'\n",
    "    elif n < 0.9:\n",
    "        return 'validate'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "df['usage'] = df.apply(assign_usage, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371bf80-90ba-4bb3-9d1e-c918f85f226f",
   "metadata": {},
   "source": [
    "## Restructuring the data directory to conform to COCO specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0a65ab-d820-4256-9bbd-cec68ee49d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, testing, and validation directories\n",
    "output_directory = '/workspace/processed_data/initial_data'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.chdir(output_directory)\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('validate', exist_ok=True)\n",
    "os.makedirs('test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67523592-eb95-4b65-bf55-cc68070a04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 5396/5396 [00:07<00:00, 719.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# use shutil to move files into directories based on the usage column\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filepath = row['filepath']\n",
    "    usage = row['usage']\n",
    "    new_path = os.path.join(output_directory, usage, f'{index}.tif')\n",
    "    shutil.copy(filepath, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56952841-a489-47ea-9ab0-e5a835d0f1ac",
   "metadata": {},
   "source": [
    "## Iterating through annotation files to create the COCO json for each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cab820f-eebb-4739-8156-00139e692b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to annotation directory\n",
    "annotation_directory = os.path.join(output_directory, 'annotations')\n",
    "os.makedirs(annotation_directory, exist_ok=True)\n",
    "os.chdir(annotation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4091962b-061b-4ea3-9f08-30110292b38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get true centroid coordinates given an input bounding box\n",
    "def get_true_centroid(xmin, ymin, xmax, ymax):\n",
    "\n",
    "    # get true centroid x coordinate\n",
    "    if xmin == 0:\n",
    "        cx = xmax - 50\n",
    "    else:\n",
    "        cx = xmin + 50\n",
    "\n",
    "    # get true centroid y coordinate\n",
    "    if ymin == 0:\n",
    "        cy = ymax - 50\n",
    "    else:\n",
    "        cy = ymin + 50\n",
    "\n",
    "    return (cx, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fcae80b-9ce3-47b4-8609-02156a4b3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_json(box_size):\n",
    "    # for each given directory:    \n",
    "    ann_number = 0\n",
    "    for usage in ['train','validate','test']:\n",
    "        # initialize COCO json for the directory\n",
    "        usage_json = {}\n",
    "        info = {'year': 2024,\n",
    "                'version': 1.0,\n",
    "                'description': f'Data to {usage} drainage culvert detection task with annotation bounding boxes of size {box_size}',\n",
    "                'contributor': 'none',\n",
    "                'url': 'none',\n",
    "                'date_created':None}\n",
    "        licenses = [{'id':1,\n",
    "                    'url':'https://creativecommons.org/publicdomain/zero/1.0/',\n",
    "                    'name':'Public Domain'}]\n",
    "        categories = [{'id':1,\n",
    "                       'name':'Drainage Culvert',\n",
    "                       'supercategory':'none'}]\n",
    "        images = []\n",
    "        annotations = []\n",
    "        # get a dataframe of only files for a given usage\n",
    "        usage_df = df[df['usage'] == usage]\n",
    "        for index, row in tqdm(usage_df.iterrows(), total=len(usage_df)):\n",
    "            # add image information to json\n",
    "            image_dict = {'id':index,\n",
    "                          'license':1,\n",
    "                          'file_name':f'{index}.tif',\n",
    "                          'height':800,\n",
    "                          'width':800,\n",
    "                          'date_captured':'none'}\n",
    "            images.append(image_dict)\n",
    "            # load in annotation xml to dict\n",
    "            tree = ET.parse(row['annpath'])\n",
    "            root = tree.getroot()\n",
    "    \n",
    "            \n",
    "            # extract bounding box from dictionary and append to json as annotation\n",
    "            for bbox in root.findall('object'):\n",
    "                xmin = int(bbox.find('bndbox/xmin').text)\n",
    "                ymin = int(bbox.find('bndbox/ymin').text)\n",
    "                xmax = int(bbox.find('bndbox/xmax').text)\n",
    "                ymax = int(bbox.find('bndbox/ymax').text)\n",
    "                cx, cy = get_true_centroid(xmin, ymin, xmax, ymax)\n",
    "                new_xmin = max(cx - (0.5 * box_size), 0)\n",
    "                new_ymin = max(cy - (0.5 * box_size), 0)\n",
    "                new_xmax = min(cx + (0.5 * box_size), 800)\n",
    "                new_ymax = min(cy + (0.5 * box_size), 800)\n",
    "                width = new_xmax - new_xmin\n",
    "                height = new_ymax - new_ymin\n",
    "\n",
    "                annotation_dict = {\n",
    "                    'id': ann_number,\n",
    "                    'image_id':index,\n",
    "                    'category_id': 1,\n",
    "                    'bbox': [new_xmin, new_ymin, width, height],\n",
    "                    'area': width*height,\n",
    "                    'segmentation':[],\n",
    "                    'iscrowd':0,\n",
    "                    }\n",
    "                annotations.append(annotation_dict)\n",
    "                ann_number += 1\n",
    "            usage_json['info'] = info\n",
    "            usage_json['licenses'] = licenses\n",
    "            usage_json['categories'] = categories\n",
    "            usage_json['images'] = images\n",
    "            usage_json['annotations'] = annotations\n",
    "            \n",
    "            json_data = json.dumps(usage_json, indent=4)\n",
    "    \n",
    "            \n",
    "        with open(f'{usage}.json', 'w') as json_file:\n",
    "            json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66a56ab7-9e52-4298-a620-fa44c41a54d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 3800/3800 [04:31<00:00, 14.01it/s]\n",
      "100%|███████████████████████████████████| 1049/1049 [00:21<00:00, 49.00it/s]\n",
      "100%|█████████████████████████████████████| 547/547 [00:06<00:00, 89.38it/s]\n"
     ]
    }
   ],
   "source": [
    "create_annotation_json(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba7e53-262e-412b-b1cd-9a7552f5c8ac",
   "metadata": {},
   "source": [
    "## Perform steps to create transfer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bf7a527-fadf-482a-9a67-239573d5cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['ND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91017d01-bdf7-4dea-88d2-63027e60345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all image files to reflect their physical location\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7b98410-0db3-4219-91b5-2e759eda5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all annotation files to match their corresponding image\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_annotations')\n",
    "    for file in os.listdir(dirpath):\n",
    "        rename = f\"{d}_{file}\"\n",
    "        new_path = os.path.join(dirpath, rename)\n",
    "        os.rename(os.path.join(dirpath, file), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c1e3420-8e01-4301-bf46-88f4fee21621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with files, annotations, and corresponding paths\n",
    "file_list = []\n",
    "for d in directories:\n",
    "    dirpath = os.path.join(dataset_path, d, f'{d}_data')\n",
    "    for file in os.listdir(dirpath):\n",
    "        if file.endswith('.tif'):\n",
    "            annotation = file[:-4]+'.xml'\n",
    "            file_list.append({\n",
    "                'filename': file, \n",
    "                'filepath':os.path.join(dirpath, file),\n",
    "                'annpath': os.path.join(dataset_path, d, f'{d}_annotations', annotation),\n",
    "                'ann': annotation\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b36bfbc9-3281-4861-8e32-be5cc0e65f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>annpath</th>\n",
       "      <th>ann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ND_237.tif</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_data/ND...</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_annotat...</td>\n",
       "      <td>ND_237.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ND_456.tif</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_data/ND...</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_annotat...</td>\n",
       "      <td>ND_456.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ND_589.tif</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_data/ND...</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_annotat...</td>\n",
       "      <td>ND_589.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ND_141.tif</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_data/ND...</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_annotat...</td>\n",
       "      <td>ND_141.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ND_364.tif</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_data/ND...</td>\n",
       "      <td>/workspace/Data_share/Data_share/ND/ND_annotat...</td>\n",
       "      <td>ND_364.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                           filepath  \\\n",
       "0  ND_237.tif  /workspace/Data_share/Data_share/ND/ND_data/ND...   \n",
       "1  ND_456.tif  /workspace/Data_share/Data_share/ND/ND_data/ND...   \n",
       "2  ND_589.tif  /workspace/Data_share/Data_share/ND/ND_data/ND...   \n",
       "3  ND_141.tif  /workspace/Data_share/Data_share/ND/ND_data/ND...   \n",
       "4  ND_364.tif  /workspace/Data_share/Data_share/ND/ND_data/ND...   \n",
       "\n",
       "                                             annpath         ann  \n",
       "0  /workspace/Data_share/Data_share/ND/ND_annotat...  ND_237.xml  \n",
       "1  /workspace/Data_share/Data_share/ND/ND_annotat...  ND_456.xml  \n",
       "2  /workspace/Data_share/Data_share/ND/ND_annotat...  ND_589.xml  \n",
       "3  /workspace/Data_share/Data_share/ND/ND_annotat...  ND_141.xml  \n",
       "4  /workspace/Data_share/Data_share/ND/ND_annotat...  ND_364.xml  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce1038-14f5-4720-9285-c807ee14ff56",
   "metadata": {},
   "source": [
    "## Ensure that image chips do not contain invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "808e78f8-b97a-4db1-80b1-a4e63e6c28c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▏                                        | 18/612 [00:00<00:10, 58.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.402823e+38\n",
      "0.0 3.402823e+38\n",
      "0.0 3.402823e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▏                                 | 108/612 [00:01<00:08, 59.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.402823e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                | 125/612 [00:02<00:13, 37.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.402823e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▉                            | 194/612 [00:03<00:06, 59.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.402823e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████▍                          | 215/612 [00:03<00:06, 60.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 3.402823e+38\n",
      "0.0 3.402823e+38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 612/612 [00:10<00:00, 58.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 out of 612 chips filtered out due to invalid pixel values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['valid'] = True\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    with rasterio.open(row['filepath'], 'r') as src:\n",
    "        data = src.read()\n",
    "    # this operation catches invalid values that are too high or too low compared to the rest of the DEM\n",
    "    df.at[index, 'valid'] = False if (np.max(data) - np.min(data)) > 10000 else True\n",
    "    if (np.max(data) - np.min(data)) > 10000:\n",
    "        print (np.min(data), np.max(data))\n",
    "\n",
    "filtered = len(df[df['valid']==False])\n",
    "\n",
    "print(f'{filtered} out of {len(df)} chips filtered out due to invalid pixel values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eee5b038-723f-4d19-9d85-9977ba1177ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['valid']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e522a6a8-5966-445d-9124-8abc010e08ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, testing, and validation directories\n",
    "output_directory = '/workspace/transfer_data'\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.chdir(output_directory)\n",
    "os.makedirs('test', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b2cfbd-626a-4db2-b24a-2c99fa6526f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 604/604 [00:01<00:00, 377.96it/s]\n"
     ]
    }
   ],
   "source": [
    "df['usage'] = 'test'\n",
    "# use shutil to move files into directories based on the usage column\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    filepath = row['filepath']\n",
    "    usage = row['usage']\n",
    "    new_path = os.path.join(output_directory, usage, f'{index}.tif')\n",
    "    shutil.copy(filepath, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d060d9b-313b-49d8-b45e-50371f08555d",
   "metadata": {},
   "source": [
    "## Iterating through annotation files to create the COCO json for each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58322a1f-552a-4d46-8f6f-5482663b0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to annotation directory\n",
    "annotation_directory = os.path.join(output_directory, 'annotations')\n",
    "os.makedirs(annotation_directory, exist_ok=True)\n",
    "os.chdir(annotation_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65fbe7-f20c-4060-9aae-17a923a622c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_annotation_json(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
